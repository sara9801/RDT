{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfab917b",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f68eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 table 크롤링에 필요한 패키지\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from html_table_parser import parser_functions\n",
    "\n",
    "# 오류(max url 초과) 해결을 위한 패키지\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "#기본 패키지들\n",
    "import os\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "# For macro rest\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 기업명 matching에 필요한 패키지\n",
    "import re\n",
    "import statistics\n",
    "from thefuzz import fuzz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#change working dir.\n",
    "os.chdir('E:/루당탕사라')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1cb70",
   "metadata": {},
   "source": [
    "# 환경정보공개시스템 URL 수집  \n",
    ": 환경정보공개시스템은 사업장정보 페이지마다 url이 존재한다. 기업명+url을 전부 수집하고 기업명 매칭을 통해 필요한 url만 골라내도록 하자.\n",
    "\n",
    "- 전체 3611건, 200건씩 설정 = 19 페이지\n",
    "- 20페이지 넘어가면 종료하는 것으로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd02874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 page is crawling...\n",
      "2 page is crawling...\n",
      "3 page is crawling...\n",
      "4 page is crawling...\n",
      "5 page is crawling...\n",
      "6 page is crawling...\n",
      "7 page is crawling...\n",
      "8 page is crawling...\n",
      "9 page is crawling...\n",
      "10 page is crawling...\n",
      "11 page is crawling...\n",
      "12 page is crawling...\n",
      "13 page is crawling...\n",
      "14 page is crawling...\n",
      "15 page is crawling...\n",
      "16 page is crawling...\n",
      "17 page is crawling...\n",
      "18 page is crawling...\n",
      "19 page is crawling...\n",
      "19 페이지에서 크롤링을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "path = \"chromedriver.exe\"\n",
    "url = \"https://www.env-info.kr/member/open/companyTotalInfoSearch.do\"\n",
    "\n",
    "wd = webdriver.Chrome(path)\n",
    "wd.maximize_window() #창 최대화\n",
    "\n",
    "# 사이트로 접속\n",
    "wd.get(url)\n",
    "wd.implicitly_wait(2)\n",
    "\n",
    "# 사용자 유형 선택 (페이지 접속했을 때 뜨는 팝업창)\n",
    "wd.find_element_by_xpath('//*[@id=\"accessUserTp_02\"]').click()\n",
    "wd.find_element_by_xpath('//*[@class=\"btn_type04\"]').click()\n",
    "\n",
    "# 페이지당 row 수 변경\n",
    "select = Select(wd.find_element_by_id('pageRows')) #한 페이지당 row수 지정\n",
    "select.select_by_value(\"200\") #200개씩 선택\n",
    "wd.find_element_by_xpath('//*[@class=\"btn_view noc\"]').click() #보기 클릭\n",
    "\n",
    "# get 'total page number'\n",
    "tot_page = wd.find_element_by_xpath('//*[@id=\"totPageNum\"]').get_attribute(\"innerText\")\n",
    "tot_page = int(tot_page)\n",
    "\n",
    "# 변수 정의\n",
    "list_urls = []\n",
    "list_names = []\n",
    "a = 0\n",
    "b = 2\n",
    "\n",
    "# 수집 시작\n",
    "while True:\n",
    "    \n",
    "    # get 'current page index'\n",
    "    current_page = wd.find_element_by_xpath('//*[@title=\"현재페이지\"]')\n",
    "    c_page = current_page.get_attribute(\"innerText\")\n",
    "    print(c_page + \" page is crawling...\")\n",
    "    \n",
    "    ## url 추출 ----------------------------------------------------------\n",
    "    main_window  = wd.current_window_handle\n",
    "    info = wd.find_elements_by_xpath('//*[@class=\"btn_view04\"]')\n",
    "    for info_link in info:\n",
    "        info_link.click()\n",
    "        tabs = wd.window_handles\n",
    "        wd.switch_to.window(tabs[1]) #2번째 탭으로 이동\n",
    "        new_url = wd.current_url #현재 페이지의 url 추출\n",
    "        list_urls.append(new_url) #기존 리스트에 본 페이지 기업명 추가\n",
    "        wd.close()\n",
    "        wd.switch_to.window(main_window) #main 탭으로 이동\n",
    "\n",
    "    ## 사업장 명 추출 -------------------------------------------------------\n",
    "    names = wd.find_elements_by_xpath('//*[@id=\"tblDocList\"]/tbody/tr/td[5]')\n",
    "    new_name = [name.get_attribute(\"innerText\") for name in names]\n",
    "    list_names.extend(new_name) #기존 리스트에 본 페이지 기업명 추가\n",
    "    \n",
    "    ## 페이지 이동 ----------------------------------------------------------\n",
    "    # get 'page index'\n",
    "    pages = wd.find_elements_by_xpath('//*[@id=\"pageViewer1\"]/a')\n",
    "\n",
    "    a+=1 #크롤링된 페이지 수 (누적)\n",
    "    b+=1 #페이지 이동용 인덱스\n",
    "    \n",
    "    if a>tot_page-1: #total page에 도달하면 종료.\n",
    "        print(c_page + \" 페이지에서 크롤링을 종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    if b>12: b=3 #10페이지 다봄, b 초기화\n",
    "        \n",
    "    #다음 페이지로 이동.\n",
    "    pages[b].click()\n",
    "    time.sleep(10) #rest. \n",
    "        \n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6df12af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name                                                url\n",
      "0   한국지엠(주) 부평공장 (본사)  https://www.env-info.kr/user/register/viewUser...\n",
      "1        한국지엠(주) 보령공장  https://www.env-info.kr/user/register/viewUser...\n",
      "2        한국지엠(주) 창원공장  https://www.env-info.kr/user/register/viewUser...\n",
      "3      ROHMKOREA 대전공장  https://www.env-info.kr/user/register/viewUser...\n",
      "4  (주)만도 brake 평택사업본부  https://www.env-info.kr/user/register/viewUser...\n"
     ]
    }
   ],
   "source": [
    "# DF로 변환, 저장\n",
    "\n",
    "df_urls = pd.DataFrame(zip(list_names, list_urls), columns = ['name', 'url'])\n",
    "print(df_urls.head())\n",
    "\n",
    "df_urls.to_csv(\"E crawling/환경정보공개시스템/env_info_urls.csv\", index=None, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c6f14",
   "metadata": {},
   "source": [
    "# ind_name matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9c25d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ind_name matching 함수: match_name 정의\n",
    "## 기존 match_name 함수에서 불필요한 코드는 제외하였음.\n",
    "\n",
    "def match_name(data, col_name):\n",
    "    \n",
    "    ind_name = pd.read_excel(\"기업명매칭/ind_name_with_CODE.xlsx\", dtype='object')\n",
    "    \n",
    "    # 1. Put columns = [CODE, 실제 기업명(=ind_name)]\n",
    "    data.insert(0, 'CODE', -1)\n",
    "    data.insert(1, 'ind_name', -1)\n",
    "      ## -1: 해당 업체명은 우리가 가진 상장기업들에 속하지 않는 이름입니다.\n",
    "    \n",
    "    \n",
    "    # 2. (주), 주식회사 등 불필요한 단어를 기준으로 split하고 다시 이어붙인다.\n",
    "    new_list = []\n",
    "    \n",
    "    for name in data[col_name]:\n",
    "        name = [i for i in re.split('\\(주\\)|\\(유\\)|㈜| |\\xa0|주식회사', name) if not i==\"\"]\n",
    "        if len(name) > 1:\n",
    "            new_list.append(''.join(name))\n",
    "        else:\n",
    "            new_list.append(name[0])\n",
    " \n",
    "    \n",
    "    for i, name in enumerate(new_list):\n",
    "    \n",
    "        ## 매칭 점수 부여 (using fuzz matching: token_sort_ratio), 상세한 설명은 결과 보고서에 기술되어 있다.\n",
    "        score = [fuzz.token_sort_ratio(name, key) for key in ind_name['trans_name']]\n",
    "        \n",
    "        ## 해당 기업명이 ind_name 중에 하나를 포함하는지의 여부 \n",
    "        contain_index = [row[0] for row in ind_name.iterrows() if row[1]['trans_name'] in name]\n",
    "        contain_name = [key for key in ind_name['trans_name'] if key in name]\n",
    "\n",
    "        if len(contain_name) == 1: ## 포함 기준으로 가져온다.\n",
    "            data.loc[i, 'CODE'] = ind_name.loc[contain_index[0], 'CODE']\n",
    "            data.loc[i, 'ind_name'] = ind_name.loc[contain_index[0], 'name']\n",
    "\n",
    "        elif len(contain_name) == 0: ## 만약 포함되는 단어가 없을 경우, pass. (기업명 없다고 간주)\n",
    "            continue\n",
    "\n",
    "        else: ## 만약 여러개 ind_name을 포함할 경우, 그 중 가장 큰 score를 준 ind_name을 부여한다.\n",
    "            score = [score[x] for x in contain_index]\n",
    "            data.loc[i, 'CODE'] = ind_name['CODE'][contain_index[score.index(max(score))]]\n",
    "            data.loc[i, 'ind_name'] = ind_name['name'][contain_index[score.index(max(score))]]\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a02399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기업명 매칭 진행.\n",
    "\n",
    "data = match_name(data = df_urls, col_name='name')\n",
    "data.to_excel('E crawling/환경정보공개시스템/env_info_urls_withName.xlsx', index=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008a39b",
   "metadata": {},
   "source": [
    "### 이후에 excel 파일을 열어서 잘못 matching이 된 ind_name을 수정하고 다시 저장하였다.\n",
    "파일 명: env_info_urls_withName_수정.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f29ca",
   "metadata": {},
   "source": [
    "# URL 접속을 통한 환경정보 데이터 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953bdaa",
   "metadata": {},
   "source": [
    "## 크롤링 CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8563ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232\n"
     ]
    }
   ],
   "source": [
    "# urls 데이터 로드\n",
    "urls = pd.read_excel('E crawling/환경정보공개시스템/env_info_urls_withName_수정.xlsx', converters={'CODE':str})\n",
    "\n",
    "# 데이터 새로 정의\n",
    "## 컬럼 industry_name, url만 갖고옴\n",
    "## 이때 industry_name = -1인 기업은 상장되지 않은, 즉 우리가 가진 데이터에 해당되지 않은 기업\n",
    "urls = urls.loc[urls['ind_name']!='-1', ['name', 'ind_name', 'url']]\n",
    "urls.reset_index(inplace=True, drop=True)\n",
    "print(len(urls.ind_name)) #총 1232개의 url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37cbce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100번째 url에서 추출되는 중입니다.\n",
      "200번째 url에서 추출되는 중입니다.\n",
      "300번째 url에서 추출되는 중입니다.\n",
      "400번째 url에서 추출되는 중입니다.\n",
      "500번째 url에서 추출되는 중입니다.\n",
      "600번째 url에서 추출되는 중입니다.\n",
      "700번째 url에서 추출되는 중입니다.\n",
      "800번째 url에서 추출되는 중입니다.\n",
      "900번째 url에서 추출되는 중입니다.\n",
      "1000번째 url에서 추출되는 중입니다.\n",
      "1100번째 url에서 추출되는 중입니다.\n",
      "1200번째 url에서 추출되는 중입니다.\n"
     ]
    }
   ],
   "source": [
    "# urls에서 크롤링 도중 오류가 발생하는 것을 방지\n",
    "session = requests.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "\n",
    "# url에서 수집한 데이터를 넣을 데이터 프레임 틀 형성\n",
    "env_info = pd.DataFrame({'name':[], 'industry_name':[],  'url':[],\n",
    "                              'water_use':[], 'water_rec':[], #용수 관련 데이터\n",
    "                              'S1':[], 'S2':[], 'S3':[], 'GHG_tot':[], #온실가스 관련 데이터\n",
    "                              'nox':[], 'sox':[], 'pm':[], 'AP_tot':[], #대기오염물질 관련 데이터\n",
    "                              'gsm':[], 'dsm':[], 'cw':[], 'waste_rec':[], 'waste_tot':[]}) #폐기물 관련 데이터\n",
    "\n",
    "\n",
    "# 크롤링 시작 -----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for index, row in urls.iterrows():\n",
    "\n",
    "    if (index+1) % 100 == 0:\n",
    "        print(str(index+1) + \"번째 url에서 추출되는 중입니다.\")\n",
    "    \n",
    "    # url 접속\n",
    "    req = session.get(row.url)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "\n",
    "    new_list = row.to_list() # 데이터 담을 list\n",
    "\n",
    "    \n",
    "    \n",
    "    ## 자원/ 에너지 ##\n",
    "    # 의무 7. 용수 사용량 -------------------------------------------------------------------------------\n",
    "\n",
    "    data7 = soup.find('div', {'id': 'inquiry07'})\n",
    "    tab7 = parser_functions.make2d(data7.table)\n",
    "    try:\n",
    "        new_list.append(pd.DataFrame(tab7)[1][0]) #용수 사용량\n",
    "    except:\n",
    "        new_list.append(-1) #NA 값엔 -1 삽입\n",
    "    try:\n",
    "        new_list.append(pd.DataFrame(tab7)[1][1]) #용수 재활용량\n",
    "    except:\n",
    "        new_list.append(-1) #NA 값엔 -1 삽입\n",
    "\n",
    "\n",
    "\n",
    "    # # 의무 8. 에너지 사용량 ----------------------------------------------------------------------------\n",
    "    ## 에너지 사용량 값은 hidden 상태여서 텍스트가 크롤링되지 않았다.\n",
    "    ## 결과적으로 데이터 사용하지 못했으므로 주석 처리함.\n",
    "\n",
    "\n",
    "    ## 온실가스/환경오염 ##\n",
    "    # 자율 11. 온실가스 관리수준 및 배출량 --------------------------------------------------------------\n",
    "    # 해당 inquiry에서 필요한 데이터들의 캡션.\n",
    "    cap11_em = '온실가스배출 실적'\n",
    "\n",
    "    data11 = soup.find('div', {'id': 'inquiry11'})\n",
    "    caption11 = data11.find_all('caption')\n",
    "    text11 = [a.get_text() for a in caption11]\n",
    "    \n",
    "    ## GHG배출 관련 데이터 추출\n",
    "    caption = caption11[text11.index(cap11_em)] #해당하는 캡션 추출\n",
    "    tab11 = caption.find_parent('table') #table로 변환\n",
    "    try:\n",
    "        df = pd.DataFrame(parser_functions.make2d(tab11)) #num of row = 4인 데이터 프레임 생성\n",
    "        GHG_list = df[1].to_list() #필요한 데이터(배출량)만 추출하여 리스트로 변환\n",
    "        if len(GHG_list) == 4:\n",
    "            new_list.extend(GHG_list)\n",
    "        elif len(GHG_list) == 0:\n",
    "            new_list.extend([-1 for a in range(4)]) #길이 0일 경우 데이터 X, -1 삽입\n",
    "        else:\n",
    "            new_list.extend([-999 for a in range(4)]) #길이 4 아닐 경우엔 -999 삽입 (따로 확인 요망)\n",
    "    except:\n",
    "        new_list.extend([-1 for a in range(4)]) #에러 뜨는 경우도 데이터 없다고 간주.\n",
    "\n",
    "\n",
    "\n",
    "    # 의무 14. 대기오염물질 배출량 ----------------------------------------------------------------------\n",
    "\n",
    "    data14 = soup.find('div', {'id': 'inquiry14'})\n",
    "    tab14 = parser_functions.make2d(data14.table)\n",
    "    try:\n",
    "        df = pd.DataFrame(tab14) #num of row = 4인 데이터 프레임 생성\n",
    "        AP_list = df[1].to_list() #필요한 데이터(배출량)만 추출하여 리스트로 변환\n",
    "        if len(AP_list) == 4:\n",
    "            new_list.extend(AP_list)\n",
    "        else:\n",
    "            new_list.extend([-999 for a in range(4)]) #길이 4 아닐 경우엔 -999 삽입 (따로 확인 요망)\n",
    "    except:\n",
    "        new_list.extend([-999 for a in range(4)]) #에러 뜨는 경우, -999 삽입 (의무 값, 따로 확인 요망)\n",
    "\n",
    "        \n",
    "\n",
    "    # 의무 16. 폐기물 발생량 ----------------------------------------------------------------------------\n",
    "\n",
    "    data16 = soup.find('div', {'id': 'inquiry16'})\n",
    "    tab16 = parser_functions.make2d(data16.table)\n",
    "    try:\n",
    "        df = pd.DataFrame(tab16) #num of row = 5인 데이터 프레임 생성\n",
    "        waste_list = df[1].to_list() #필요한 데이터(배출량)만 추출하여 리스트로 변환\n",
    "        if len(waste_list) == 5:\n",
    "            new_list.extend(waste_list)\n",
    "        else:\n",
    "            new_list.extend([-999 for a in range(5)]) #길이 6 아닐 경우엔 -999 삽입 (따로 확인 요망)\n",
    "    except:\n",
    "        new_list.extend([-999 for a in range(5)]) #에러 뜨는 경우, -999 삽입 (의무 값, 따로 확인 요망)\n",
    "\n",
    "\n",
    "\n",
    "    # 최종: 리스트를 데이터 프레임의 한 row로 삽입\n",
    "    env_info.loc[index] = new_list\n",
    "    \n",
    "    # 잠깐 휴식\n",
    "    time.sleep(1)\n",
    "    \n",
    "# 크롤링 종료 -----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2182c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "env_info.to_csv(\"E crawling/환경정보공개시스템/env_info.csv\", index=None, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb7a0e",
   "metadata": {},
   "source": [
    "##### encoding 저장오류로 인해 UTF-8으로 저장한 뒤, 다시 메모장으로 열어서 ANSI인 CSV파일로 새로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af721179",
   "metadata": {},
   "source": [
    "# 크롤링 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e22f9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_env = pd.read_csv('E crawling/환경정보공개시스템/env_info.csv', encoding='ANSI') #데이터 load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c86e7",
   "metadata": {},
   "source": [
    "### 텍스트 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27950eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 텍스트에 대해서, 감소/증가에 대한 퍼센트를 가지고 오는 함수 정의\n",
    "\n",
    "def ratio(x) :\n",
    "    if type(x) == float :\n",
    "        return 'NaN'\n",
    "    elif x.find('전년도입력정보없음') != -1 :\n",
    "        return 'NaN'\n",
    "    \n",
    "    elif x.find('전년과동일') != -1 :\n",
    "        return '0'\n",
    "    \n",
    "    #감소/증가 퍼센트가 존재하는 텍스트\n",
    "    elif x.find('전년대비') != -1 :\n",
    "        \n",
    "        #증가일 경우: 전년대비의 '비'부터~ %(증가)의 '%' 사이의 값까지 추출\n",
    "        if x.find('증가') != -1 :\n",
    "            return x[(x.find('비')+1):(x.find('%'))]\n",
    "        \n",
    "        #감소일 경우: 증가일 경우와 동일한 형식으로 텍스트 추출\n",
    "        elif x.find('감소') != -1 :\n",
    "            return '-' + x[(x.find('비')+1):(x.find('%'))]\n",
    "        \n",
    "        #이외의 경우: 오류\n",
    "        else : \n",
    "            return '오류' \n",
    "    else : \n",
    "        return '오류' #위의 모든 case에 해당되지 않을 때, 오류라고 표기하고 추후에 확인하였다. (그러나 오류 존재하지 않았음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d53cdf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 거칠 columns name\n",
    "var_list = ['water_use', 'water_rec', 'S1', 'S2', 'S3', 'GHG_tot',\n",
    "           'nox', 'sox', 'pm', 'AP_tot', 'gsm', 'dsm', 'cw', 'waste_rec', 'waste_tot']\n",
    "\n",
    "#없앨 문자열들 list\n",
    "string_list = [' ', '\\r', '\\n', '\\t']\n",
    "\n",
    "\n",
    "# 문자열 전처리 코드 --------------------------------------------------------------------------------------------------\n",
    "for var in var_list:\n",
    "    \n",
    "    ## string_list에 있는 문자열 제거\n",
    "    for string in string_list:\n",
    "        data_env[var] = data_env[var].str.replace(string,\"\") \n",
    "    \n",
    "    ## 전년도 대비 증감비율 추출\n",
    "    new_list = []\n",
    "    for i in range(len(data_env[var])) :\n",
    "        new_list.append(ratio(data_env.loc[i, var])) #ratio 함수 사용하여 퍼센트 추출\n",
    "    data_env['new_'+var] = new_list #새로운 column에 퍼센트 추출한 리스트 삽입\n",
    "    \n",
    "    ## ton을 기준으로 문자열 split, ton 앞의 숫자만 추출한다. (이때 ','를 삭제하고 dtype은 숫자형식으로 바꿔준다.)\n",
    "    for i, text in enumerate(data_env[var]):\n",
    "        if type(text)==float:\n",
    "            continue #nan인 경우 pass.\n",
    "        data_env.loc[i, var] = float(text.split('ton')[0].replace(\",\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53959984",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = pd.read_excel(\"종목코드.xlsx\", dtype='object')\n",
    "\n",
    "data_env = pd.merge(corp, data_env, how='right', left_on='종목명', right_on='industry_name')\n",
    "data_env.drop('종목명', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18b93627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['종목코드', 'name', 'industry_name', 'url', 'water_use', 'water_rec', 'S1',\n",
      "       'S2', 'S3', 'GHG_tot', 'nox', 'sox', 'pm', 'AP_tot', 'gsm', 'dsm', 'cw',\n",
      "       'waste_rec', 'waste_tot', 'new_water_use', 'new_water_rec', 'new_S1',\n",
      "       'new_S2', 'new_S3', 'new_GHG_tot', 'new_nox', 'new_sox', 'new_pm',\n",
      "       'new_AP_tot', 'new_gsm', 'new_dsm', 'new_cw', 'new_waste_rec',\n",
      "       'new_waste_tot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data_env.columns)\n",
    "\n",
    "# 여기서 우리에게 필요한 column만 가져온다.\n",
    "data_env = data_env[['종목코드', 'industry_name', 'name', 'new_water_use', 'water_use', 'new_water_rec', 'water_rec',\n",
    "                     'nox', 'sox', 'pm', 'new_nox', 'new_sox', 'new_pm',\n",
    "                     'new_waste_tot', 'waste_tot', 'new_waste_rec', 'waste_rec', \n",
    "                     'new_S1', 'new_S2', 'S1', 'S2', 'S3']]\n",
    "\n",
    "# column명 알아보기 쉽게 변경.\n",
    "data_env.columns = ['CODE', 'ind_name', '사업장명', '용수 증감비율', '용수', '용수재활용 증감비율', '용수재활용',\n",
    "                    'NOX', 'SOX', 'PM', 'NOX 증감비율', 'SOX 증감비율', 'PM 증감비율',\n",
    "                    '폐기물 증감비율', '폐기물', '폐기물재활용 증감비율', '폐기물재활용',\n",
    "                    '온실가스1 증감비율', '온실가스2 증감비율', '온실가스1', '온실가스2', '온실가스3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f0ca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 편의를 위해 데이터프레임 columns 명 재정렬\n",
    "data_env = data_env[['CODE', 'ind_name','사업장명','용수 증감비율','용수','용수재활용 증감비율','용수재활용',\n",
    "                     '폐기물 증감비율', '폐기물', '폐기물재활용 증감비율', '폐기물재활용',\n",
    "                     'PM 증감비율', 'PM', 'NOX 증감비율', 'NOX', 'SOX 증감비율', 'SOX',\n",
    "                     '온실가스1 증감비율', '온실가스2 증감비율', '온실가스1', '온실가스2', '온실가스3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6365903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CODE', 'ind_name', '사업장명', '용수 증감비율', '용수', '용수재활용 증감비율', '용수재활용',\n",
       "       '폐기물 증감비율', '폐기물', '폐기물재활용 증감비율', '폐기물재활용', 'PM 증감비율', 'PM', 'NOX 증감비율',\n",
       "       'NOX', 'SOX 증감비율', 'SOX', '온실가스1 증감비율', '온실가스2 증감비율', '온실가스1', '온실가스2',\n",
       "       '온실가스3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_env.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df146c75",
   "metadata": {},
   "source": [
    "## 전년도 용량 계산하는 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fccf655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prev(data, column):\n",
    "    \n",
    "    # 전년도 데이터 생성하는 함수\n",
    "    ## input: data, column name (ex. 용수재활용)\n",
    "        # 'column' argument must be list.\n",
    "    ## ouput: 용수재활용 증감비율 column -> 전년도 용수재활용 column으로 변환된 data\n",
    "    \n",
    "    for col in column:\n",
    "        \n",
    "        old_col = str(col) + ' 증감비율'\n",
    "        new_col = '전년도 ' + str(col)\n",
    "\n",
    "        col_data = [float(str(x).replace(',', '')) for x in data[col]]\n",
    "        rate_data = [str(x).replace(',', '') for x in data[old_col]]\n",
    "        \n",
    "        data[col] = col_data\n",
    "        data[old_col] = [0 if rate_data[i]=='∞' else np.NaN if rate_data[i]=='-100' else round(100*col_data[i]/(100+float(rate_data[i])), 2) for i in range(data.shape[0])]\n",
    "        data.rename(columns={old_col:new_col}, inplace=True)\n",
    "        \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ef7704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODE          0\n",
       "ind_name      0\n",
       "전년도 용수        0\n",
       "용수            0\n",
       "전년도 용수재활용     0\n",
       "용수재활용         0\n",
       "전년도 폐기물       0\n",
       "폐기물           0\n",
       "전년도 폐기물재활용    0\n",
       "폐기물재활용        0\n",
       "전년도 PM        0\n",
       "PM            0\n",
       "전년도 NOX       0\n",
       "NOX           0\n",
       "전년도 SOX       0\n",
       "SOX           0\n",
       "전년도 온실가스1     0\n",
       "전년도 온실가스2     0\n",
       "온실가스1         0\n",
       "온실가스2         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prev(data_env, column=['용수', '용수재활용', '폐기물', '폐기물재활용', 'PM', 'NOX', 'SOX', '온실가스1', '온실가스2'])\n",
    "\n",
    "grouped_env = round(data_env.groupby(['CODE', 'ind_name']).sum().reset_index(), 2)\n",
    "grouped_env.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea4bc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column: 온실가스 1 + 온실가스 2 = 온실가스 scope1 + scope2\n",
    "grouped_env['전년도 온실가스'] = grouped_env['전년도 온실가스1'] + grouped_env['전년도 온실가스2']\n",
    "grouped_env['온실가스'] = grouped_env['온실가스1'] + grouped_env['온실가스2']\n",
    "\n",
    "# 기존 변수 제거\n",
    "grouped_env.drop(['전년도 온실가스1', '전년도 온실가스2', '온실가스1', '온실가스2'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# make a new column: 대기오염물질 총합 = PM + NOX + SOX\n",
    "grouped_env['전년도 대기오염물질'] = grouped_env['전년도 PM'] + grouped_env['전년도 NOX'] + grouped_env['전년도 SOX']\n",
    "grouped_env['대기오염물질'] = grouped_env['PM'] + grouped_env['NOX'] + grouped_env['SOX']\n",
    "\n",
    "# 기존 변수 제거\n",
    "grouped_env.drop(['전년도 PM', '전년도 NOX', '전년도 SOX', 'PM', 'NOX', 'SOX'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1b9ea5",
   "metadata": {},
   "source": [
    "## 전년도 대비 증감율 계산하는 함수 생성\n",
    "주의: NA는 값이 없다는 게 아니라 (애초에 DF에는 NA가 하나도 없음) 전년 값이 0이라 나눌 수 없다는 표시."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92ca6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yoy(data, column):\n",
    "    \n",
    "    # 전년도 대비 증감율 생성하는 함수\n",
    "    ## input: data, column name (ex. 용수 발생량)\n",
    "        # 'column' argument must be list.\n",
    "    ## ouput: 전년도 용량 column -> 증감 비율 column으로 변환된 data\n",
    "    \n",
    "    # Q. 다시 원래 증감 비율로 돌리는 이유가 뭔가요?\n",
    "    # A. 사업장이 여러개인 기업이 있기 때문에, 증감 비율을 구하려면 전체 사업장에 대한 전년도 값을 더해줘야 하기 때문입니다.\n",
    "    \n",
    "    for col in column:\n",
    "        \n",
    "        old_col = '전년도 ' + str(col)\n",
    "        new_col = str(col) + '증감비율'\n",
    "\n",
    "        data[old_col] = [np.inf if data[col][i]==data[old_col][i]==0 else round(100*data[col][i]/data[old_col][i], 2) for i in range(data.shape[0])] #0을 0으로 나누는 것은 불가능하므로 조건문을 사용하여 inf로 변환시킨다.\n",
    "        \n",
    "        data.rename(columns={old_col:new_col}, inplace=True)\n",
    "        \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a4f3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_yoy(grouped_env, ['용수', '용수재활용', '폐기물', '폐기물재활용', '온실가스', '대기오염물질'])\n",
    "\n",
    "grouped_env.columns = [x if x in ['CODE', 'ind_name'] else str(x)+'2020' for x in grouped_env.columns]\n",
    "grouped_env.rename(columns={'CODE':'종목코드', 'ind_name': '회사명'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "997aa355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목코드</th>\n",
       "      <th>회사명</th>\n",
       "      <th>용수증감비율2020</th>\n",
       "      <th>용수2020</th>\n",
       "      <th>용수재활용증감비율2020</th>\n",
       "      <th>용수재활용2020</th>\n",
       "      <th>폐기물증감비율2020</th>\n",
       "      <th>폐기물2020</th>\n",
       "      <th>폐기물재활용증감비율2020</th>\n",
       "      <th>폐기물재활용2020</th>\n",
       "      <th>온실가스증감비율2020</th>\n",
       "      <th>온실가스2020</th>\n",
       "      <th>대기오염물질증감비율2020</th>\n",
       "      <th>대기오염물질2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000050</td>\n",
       "      <td>경방</td>\n",
       "      <td>91.00</td>\n",
       "      <td>8296.56</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.11</td>\n",
       "      <td>13.41</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>16989.70</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000080</td>\n",
       "      <td>하이트진로</td>\n",
       "      <td>102.87</td>\n",
       "      <td>7191537.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.58</td>\n",
       "      <td>124808.69</td>\n",
       "      <td>123.69</td>\n",
       "      <td>123724.85</td>\n",
       "      <td>97.10</td>\n",
       "      <td>158804.10</td>\n",
       "      <td>59.31</td>\n",
       "      <td>82.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000100</td>\n",
       "      <td>유한양행</td>\n",
       "      <td>119.90</td>\n",
       "      <td>148433.00</td>\n",
       "      <td>125.60</td>\n",
       "      <td>10647.0</td>\n",
       "      <td>146.50</td>\n",
       "      <td>1539.96</td>\n",
       "      <td>124.40</td>\n",
       "      <td>749.49</td>\n",
       "      <td>117.72</td>\n",
       "      <td>16672.00</td>\n",
       "      <td>33.86</td>\n",
       "      <td>2.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000120</td>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>95.74</td>\n",
       "      <td>684772.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126.02</td>\n",
       "      <td>4279.16</td>\n",
       "      <td>6634.85</td>\n",
       "      <td>496.95</td>\n",
       "      <td>106.77</td>\n",
       "      <td>213463.76</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000150</td>\n",
       "      <td>두산</td>\n",
       "      <td>86.31</td>\n",
       "      <td>1744046.00</td>\n",
       "      <td>95.51</td>\n",
       "      <td>131257.0</td>\n",
       "      <td>127.08</td>\n",
       "      <td>91674.44</td>\n",
       "      <td>76.29</td>\n",
       "      <td>46545.87</td>\n",
       "      <td>93.41</td>\n",
       "      <td>317346.35</td>\n",
       "      <td>71.05</td>\n",
       "      <td>79.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     종목코드     회사명  용수증감비율2020      용수2020  용수재활용증감비율2020  용수재활용2020  \\\n",
       "0  000050      경방       91.00     8296.56            inf        0.0   \n",
       "1  000080   하이트진로      102.87  7191537.00            inf        0.0   \n",
       "2  000100    유한양행      119.90   148433.00         125.60    10647.0   \n",
       "3  000120  CJ대한통운       95.74   684772.00            inf        0.0   \n",
       "4  000150      두산       86.31  1744046.00          95.51   131257.0   \n",
       "\n",
       "   폐기물증감비율2020    폐기물2020  폐기물재활용증감비율2020  폐기물재활용2020  온실가스증감비율2020  \\\n",
       "0        99.11      13.41             inf        0.00           inf   \n",
       "1       123.58  124808.69          123.69   123724.85         97.10   \n",
       "2       146.50    1539.96          124.40      749.49        117.72   \n",
       "3       126.02    4279.16         6634.85      496.95        106.77   \n",
       "4       127.08   91674.44           76.29    46545.87         93.41   \n",
       "\n",
       "    온실가스2020  대기오염물질증감비율2020  대기오염물질2020  \n",
       "0   16989.70             inf        0.00  \n",
       "1  158804.10           59.31       82.86  \n",
       "2   16672.00           33.86        2.15  \n",
       "3  213463.76             inf        0.00  \n",
       "4  317346.35           71.05       79.24  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_env.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523aedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_env.to_excel(\"E crawling/result/환경정보_2020.xlsx\", index=None, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
