{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4862fb",
   "metadata": {},
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f6c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 table 크롤링에 필요한 패키지\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from html_table_parser import parser_functions\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# 오류(max url 초과) 해결을 위한 패키지\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "#기본 패키지들\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan as NA\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from collections import Counter\n",
    "from more_itertools import locate\n",
    "\n",
    "# For macro rest\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# pdf 다운로드 창 option 변경 \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# ind_name 매칭\n",
    "import re\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from thefuzz import fuzz\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "#change working dir.\n",
    "import os\n",
    "os.chdir('E:/루당탕사라')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9437a9",
   "metadata": {},
   "source": [
    "# 데이터 1: ISMS-P발급현황 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff797e",
   "metadata": {},
   "source": [
    "## KISA 정보보호 및 개인정보보호관리체계 인증서 ISMS-P 발급현황 추출\n",
    "https://isms.kisa.or.kr/main/ispims/issue;jsessionid=8151A7D57431C6C791DBD4DD02D0F0F9/?certificationMode=list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc99e4b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 page is crawled...\n",
      "2 page is crawled...\n",
      "3 page is crawled...\n",
      "4 page is crawled...\n",
      "5 page is crawled...\n",
      "6 page is crawled...\n",
      "7 page is crawled...\n",
      "8 page is crawled...\n",
      "9 page is crawled...\n",
      "10 page is crawled...\n",
      "11 page is crawled...\n",
      "12 page is crawled...\n",
      "13 page is crawled...\n",
      "14 page is crawled...\n",
      "15 page is crawled...\n",
      "16 page is crawled...\n",
      "17 page is crawled...\n",
      "18 page is crawled...\n",
      "19 page is crawled...\n",
      "20 page is crawled...\n",
      "21 page is crawled...\n",
      "22 page is crawled...\n",
      "23 page is crawled...\n",
      "24 page is crawled...\n",
      "25 page is crawled...\n",
      "26 page is crawled...\n",
      "27 page is crawled...\n",
      "28 page is crawled...\n",
      "29 page is crawled...\n",
      "30 page is crawled...\n",
      "31 page is crawled...\n",
      "32 page is crawled...\n",
      "33 page is crawled...\n",
      "34 page is crawled...\n",
      "35 page is crawled...\n",
      "36 page is crawled...\n",
      "37 page is crawled...\n",
      "38 page is crawled...\n",
      "39 page is crawled...\n",
      "40 page is crawled...\n",
      "41 page is crawled...\n",
      "42 page is crawled...\n",
      "43 page is crawled...\n",
      "44 page is crawled...\n",
      "45 page is crawled...\n",
      "46 page is crawled...\n",
      "47 page is crawled...\n",
      "48 page is crawled...\n",
      "49 page is crawled...\n",
      "50 page is crawled...\n",
      "51 page is crawled...\n",
      "52 page is crawled...\n",
      "53 page is crawled...\n",
      "54 page is crawled...\n",
      "55 page is crawled...\n",
      "56 page is crawled...\n",
      "57 page is crawled...\n",
      "58 page is crawled...\n",
      "59 page is crawled...\n",
      "60 page is crawled...\n",
      "61 page is crawled...\n",
      "62 page is crawled...\n",
      "63 page is crawled...\n",
      "64 page is crawled...\n",
      "65 page is crawled...\n",
      "66 page is crawled...\n",
      "67 page is crawled...\n",
      "68 page is crawled...\n",
      "69 page is crawled...\n",
      "70 page is crawled...\n",
      "71 page is crawled...\n",
      "72 page is crawled...\n",
      "73 page is crawled...\n",
      "74 page is crawled...\n",
      "75 page is crawled...\n",
      "76 page is crawled...\n",
      "77 page is crawled...\n",
      "78 page is crawled...\n",
      "79 page is crawled...\n",
      "80 page is crawled...\n",
      "81 page is crawled...\n",
      "82 page is crawled...\n",
      "83 page is crawled...\n",
      "84 page is crawled...\n",
      "85 page is crawled...\n",
      "86 page is crawled...\n",
      "87 page is crawled...\n",
      "88 page is crawled...\n",
      "89 page is crawled...\n",
      "90 page is crawled...\n",
      "91 page is crawled...\n",
      "92 page is crawled...\n",
      "93 page is crawled...\n",
      "94 page is crawled...\n",
      "95 page is crawled...\n",
      "96 page is crawled...\n",
      "97 page is crawled...\n",
      "time : 347.7062976360321\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "path = \"chromedriver.exe\"\n",
    "wd = webdriver.Chrome(path)\n",
    "wd.maximize_window() #창 최대화\n",
    "\n",
    "\n",
    "# 크롤링 준비 ---------------------------------------\n",
    "num_list = [] ## 인증번호 list (number)\n",
    "nam_list = [] ## 업체명 list (name)\n",
    "ran_list = [] ## 인증범위 list (range)\n",
    "exp_list = [] ## 유효기간 list (expiration)\n",
    "rem_list = [] ## 취소여부(유지, 취소) list (remain)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "for page in range(97): #총 페이지 수\n",
    "    \n",
    "    print(f\"{page+1} page is crawled...\")\n",
    "    \n",
    "    # url을 통한 페이지 이동\n",
    "    url = 'https://isms.kisa.or.kr/main/ispims/issue;jsessionid=B9ACE2CD50B2C5A3FF191D26AC3F3435/?searchCondition=&searchKeyword=&certificationMode=list&crtfYear=&pageIndex=' + str(page+1)\n",
    "    \n",
    "    # 사이트로 접속\n",
    "    wd.get(url)\n",
    "    wd.implicitly_wait(3)\n",
    "    \n",
    "    \n",
    "    #크롤링 시작\n",
    "    nums = wd.find_elements_by_xpath('//*[@id=\"listForm\"]/table/tbody/tr/td[1]')\n",
    "    nams = wd.find_elements_by_xpath('//*[@id=\"listForm\"]/table/tbody/tr/td[2]')\n",
    "    rans = wd.find_elements_by_xpath('//*[@id=\"listForm\"]/table/tbody/tr/td[3]')\n",
    "    exps = wd.find_elements_by_xpath('//*[@id=\"listForm\"]/table/tbody/tr/td[4]')\n",
    "    rems = wd.find_elements_by_xpath('//*[@id=\"listForm\"]/table/tbody/tr/td[5]')\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    new_nums = [i.get_attribute('innerText') for i in nums]\n",
    "    new_names = [i.get_attribute('innerText') for i in nams]\n",
    "    new_rans = [i.get_attribute('innerText') for i in rans]\n",
    "    new_exps = [i.get_attribute('innerText') for i in exps]\n",
    "    new_rems = [i.get_attribute('innerText') for i in rems]\n",
    "\n",
    "    # 리스트에 추가 \n",
    "    num_list.extend(new_nums)\n",
    "    nam_list.extend(new_names)\n",
    "    ran_list.extend(new_rans)\n",
    "    exp_list.extend(new_exps)\n",
    "    rem_list.extend(new_rems)\n",
    "    \n",
    "    time.sleep(3)\n",
    "\n",
    "time.sleep(10)\n",
    "wd.quit()\n",
    "\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58731f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "인증번호       0\n",
       "업체(기관)명    0\n",
       "인증범위       0\n",
       "유효기간       0\n",
       "취소여부       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'인증번호':num_list, '업체(기관)명':nam_list, '인증범위':ran_list, '유효기간':exp_list, '취소여부':rem_list})\n",
    "\n",
    "# NA 확인.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1fd45",
   "metadata": {},
   "source": [
    "## ind_name matching\n",
    "매칭 기준 파일: ind_name_with_CODE.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89932082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의\n",
    "## 함수를 매번 불러오는 이유는, 파일 상황에 따라 조금씩 코드 수정해야 하는 경우가 빈번하다.\n",
    "## 따라서 번거롭더라도 함수를 매 시트에서 적용해주고 조건에 따라 코드를 재정의한다.\n",
    "\n",
    "def match_name(data, col_name):\n",
    "    \n",
    "    # 1. 기업명 csv 불러오기 (기준 파일)\n",
    "    ind_name = pd.read_excel(\"기업명매칭/ind_name_with_CODE.xlsx\", dtype='object')\n",
    "    \n",
    "    # 2. Put columns = [CODE, 실제 기업명]\n",
    "    data.insert(0, 'CODE', -1)\n",
    "    data.insert(1, 'ind_name', -1)\n",
    "      ## -1 = 해당 업체명은 우리가 가진 상장기업들에 속하지 않는 이름입니다.\n",
    "    \n",
    "    # 3. (주), 주식회사, 본부, 공장 등의 불필요한 단어를 포함한 단어들을 제거한다.\n",
    "    new_list = []\n",
    "    remove_word = ['본부', '공장', '사업장', '캠퍼스', '발전소', '발전처']\n",
    "    \n",
    "    for name in data[col_name]:\n",
    "        name = [i for i in re.split('\\(주\\)|㈜| |\\xa0|주식회사', name) if not i==\"\"]\n",
    "        if len(name) > 1:\n",
    "            new_list.append(''.join([x for x in name if not any(word in x for word in remove_word)]))\n",
    "        else:\n",
    "            new_list.append(name[0])\n",
    "    \n",
    "    # 4. 그렇게 생성된 name_list와 우리가 가진 기업명(ind_name)을 매칭하여 기업명을 부여한다.\n",
    "    for i, name in enumerate(new_list):\n",
    "    \n",
    "        ## 매칭 점수 부여 (using fuzz matching: token_sort, token_set_ratio)\n",
    "        score = [fuzz.token_sort_ratio(name, key) for key in ind_name['trans_name']]\n",
    "        ## 해당 기업명이 ind_name 중에 하나를 포함하는지의 여부 \n",
    "        contain_index = [row[0] for row in ind_name.iterrows() if row[1]['trans_name'] in name]\n",
    "        contain_name = [key for key in ind_name['trans_name'] if key in name]\n",
    "\n",
    "        if len(contain_name) == 1: ## 포함 기준으로 가져온다.\n",
    "            data.loc[i, 'CODE'] = ind_name.loc[contain_index[0], 'CODE']\n",
    "            data.loc[i, 'ind_name'] = ind_name.loc[contain_index[0], 'name']\n",
    "\n",
    "        elif len(contain_name) == 0: ## 만약 포함되는 단어가 없을 경우, pass. (기업명 없다고 간주)\n",
    "            continue\n",
    "\n",
    "        else: ## 만약 여러개 ind_name을 포함할 경우, 그 중 가장 큰 score를 준 ind_name을 부여한다.\n",
    "            score = [score[x] for x in contain_index]\n",
    "            data.loc[i, 'CODE'] = ind_name['CODE'][contain_index[score.index(max(score))]]\n",
    "            data.loc[i, 'ind_name'] = ind_name['name'][contain_index[score.index(max(score))]]\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67e00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = match_name(data = data, col_name='업체(기관)명')\n",
    "data.rename(columns={'CODE':'종목코드', 'ind_name': '회사명'}, inplace=True)\n",
    "data.to_excel(\"S crawling/result/ISMS-P발급현황_2021.xlsx\", index=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420d0d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47039b6",
   "metadata": {},
   "source": [
    "# 데이터 2: 잡플래닛 기업평점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c579d91a",
   "metadata": {},
   "source": [
    "[STEP]\n",
    "1) 종목코드와 기업명을 불러온다. (기업명은 각 기업에 대해 기존 기업명+변환한 기업명들 = '총 기업명들'을 모두 사용한다.)  \n",
    "2) 잡플래닛 사이트에 접속하여 기업명을 검색한 URL로 접속한다.   \n",
    "3) 검색 결과에 나온 잡플래닛_기업명, 잡플래닛_기업평점을 모두 추출한다.  \n",
    "4) '총 기업명들'과 대조했을 때 가장 높은 점수를 주는 잡플래닛_기업명, 잡플래닛_기업평점을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd370fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1) 종목코드와 기업명을 불러온다.\n",
    "\n",
    "ind_name = pd.read_excel('기업명매칭/ind_name_with_CODE.xlsx', dtype='object')\n",
    "\n",
    "# 평점 들어갈 df 생성\n",
    "score = pd.DataFrame({'CODE':ind_name['CODE'], 'name':ind_name['name'], 'name_ext':-1, 'score':-1})\n",
    "score.drop_duplicates(inplace=True)\n",
    "score.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9036648d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working time : 2695.412191390991\n"
     ]
    }
   ],
   "source": [
    "# 코드 돌아가는 시간 계산\n",
    "start_time = time.time()\n",
    "\n",
    "path = \"chromedriver.exe\"\n",
    "\n",
    "wd = webdriver.Chrome(path)\n",
    "wd.maximize_window() #창 최대화\n",
    "\n",
    "for i, uniq_name in enumerate(score.name.to_list()):\n",
    "    co_ext = []\n",
    "    score_ext = []\n",
    "    \n",
    "    # uniq_name에 해당하는 모든 기업명 불러오기\n",
    "    all_name = ind_name.loc[ind_name['index']==i, 'trans_name']\n",
    "    \n",
    "    \n",
    "    # STEP 2) 잡플래닛 사이트에 접속하여 기업명을 검색한 URL로 접속한다. \n",
    "    for name in all_name:\n",
    "        if '&' in name: #url encoding\n",
    "            name = name.replace('&', '%26') \n",
    "        \n",
    "        url = 'https://www.jobplanet.co.kr/search?query=' + name + '&category=search_new&search_keyword_hint_id=&_rs_con=seach&_rs_act=keyword_search'\n",
    "\n",
    "        wd.get(url)\n",
    "        wd.implicitly_wait(3)\n",
    "        \n",
    "        # STEP 3) 검색 결과에 나온 잡플래닛_기업명, 잡플래닛_기업평점을 모두 추출한다.\n",
    "        try:    \n",
    "            #모든 기업명 추출\n",
    "            co_e = wd.find_elements_by_xpath('//*[@id=\"mainContents\"]/div[1]/div/div[2]/div[1]/div/a') #table element로 접근\n",
    "            co_ext.extend([i.get_attribute(\"innerText\").replace('(주)', '') for i in co_e])\n",
    "            \n",
    "            #모든 기업평점 추출\n",
    "            score_e = wd.find_elements_by_xpath('//*[@id=\"mainContents\"]/div[1]/div/div[2]/div[1]/div/span[3]') #table element로 접근\n",
    "            score_ext.extend([x.get_attribute(\"innerText\") for x in score_e])\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # STEP 4) '총 기업명들'과 대조했을 때 가장 높은 점수를 주는 잡플래닛_기업명, 잡플래닛_기업평점을 가져온다.\n",
    "    \n",
    "    # 만약 co_ext와 score_ext의 길이가 다르거나 길이 0이라면 for문 skip. (데이터 잘못 추출된 것)        \n",
    "    if not (len(co_ext) == len(score_ext))&(len(co_ext) > 0):\n",
    "        continue\n",
    "        \n",
    "    if len(set(all_name)&set(co_ext)) > 0:\n",
    "        final_co = list(set(all_name)&set(co_ext))[0]\n",
    "        final_score = score_ext[co_ext.index(final_co)]\n",
    "    \n",
    "    else:\n",
    "        final_co = co_ext[0]\n",
    "        final_score = score_ext[0]\n",
    "    \n",
    "    #최종 df에 삽입\n",
    "    score.loc[i, 'name_ext'] = final_co\n",
    "    score.loc[i, 'score'] = final_score\n",
    "    \n",
    "    # 잠시 rest.\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# 코드 돌아간 시간 print.\n",
    "print(f\"Working time : {time.time() - start_time}\")\n",
    "\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09aa8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score.rename(columns={'CODE':'종목코드', 'name': '회사명'}, inplace=True)\n",
    "score.to_excel(\"S crawling/result/잡플래닛평점_2021.xlsx\", index=None, encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98deaf2a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de659bca",
   "metadata": {},
   "source": [
    "# 데이터 3: 정보보호 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2f58a",
   "metadata": {},
   "source": [
    "### 정보보호 공시 종합포털 크롤링\n",
    "https://isds.kisa.or.kr/publish/list.do?pageNum=1&limit=700\n",
    "\n",
    "\n",
    " 1) 공시 현황에 접속하여 보이는 표를 전부 크롤링한다. (기업명, 업종, 게시일 컬럼) = 기업의 정보보호 공시 현황 추출   \n",
    " 2) 기업 매칭을 통해 필요 없는 기업을 제거한다. = 기업명 매칭  \n",
    " 3) 기업명 매칭된, 필요한 기업만 링크로 접속하여(사이트의 기업명들 클릭하면 접속됨.) 내부의 정보보호 현황을 크롤링한다. = 정보보호 현황 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f6e67",
   "metadata": {},
   "source": [
    "## 1) 기업의 정보보호 공시 현황 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f2dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 크롤링 코드 ##\n",
    "\n",
    "#페이지로 접속, limit=700: 한 페이지 당 최대 기업수 700개로 설정\n",
    "url = 'https://isds.kisa.or.kr/publish/list.do?pageNum=1&limit=700'\n",
    "path = \"chromedriver.exe\"\n",
    "\n",
    "wd = webdriver.Chrome(path)\n",
    "wd.maximize_window() #창 최대화\n",
    "\n",
    "# 사이트로 접속\n",
    "wd.get(url)\n",
    "wd.implicitly_wait(3)\n",
    "\n",
    "# element 추출\n",
    "names = wd.find_elements_by_xpath('/html/body/div/container/div/div/div[2]/div/table/tbody/tr/td[3]/a') #기업명\n",
    "tofs = wd.find_elements_by_xpath('/html/body/div/container/div/div/div[2]/div/table/tbody/tr/td[4]/a') #업종\n",
    "dates = wd.find_elements_by_xpath('/html/body/div/container/div/div/div[2]/div/table/tbody/tr/td[5]') #게시일\n",
    "\n",
    "# element 내의 텍스트 추출\n",
    "name_list = [name.get_attribute('innerText') for name in names]\n",
    "tof_list = [tof.get_attribute('innerText') for tof in tofs]\n",
    "date_list = [date.get_attribute('innerText') for date in dates]\n",
    "\n",
    "time.sleep(10) #rest.\n",
    "wd.quit() #종료.\n",
    "\n",
    "# 최종 데이터프레임 저장.\n",
    "info_protect = pd.DataFrame({'기업명':name_list, '업종':tof_list, '게시일':date_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6faa60",
   "metadata": {},
   "source": [
    "## 2) 기업명 매칭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04215144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 정의\n",
    "## 함수를 매번 불러오는 이유는, 파일 상황에 따라 조금씩 코드 수정해야 하는 경우가 빈번하다.\n",
    "## 따라서 번거롭더라도 함수를 매 시트에서 적용해주고 조건에 따라 코드를 재정의한다.\n",
    "\n",
    "def match_name(data, col_name):\n",
    "    \n",
    "    # 1. 기업명 csv 불러오기 (기준 파일)\n",
    "    ind_name = pd.read_excel(\"기업명매칭/ind_name_with_CODE.xlsx\", dtype='object')\n",
    "    \n",
    "    # 2. Put columns = [CODE, 실제 기업명]\n",
    "    data.insert(0, 'CODE', -1)\n",
    "    data.insert(1, 'ind_name', -1)\n",
    "      ## -1 = 해당 업체명은 우리가 가진 상장기업들에 속하지 않는 이름입니다.\n",
    "    \n",
    "    # 3. (주), 주식회사, 본부, 공장 등의 불필요한 단어를 포함한 단어들을 제거한다.\n",
    "    new_list = []\n",
    "    remove_word = ['본부', '공장', '사업장', '캠퍼스', '발전소', '발전처']\n",
    "    \n",
    "    for name in data[col_name]:\n",
    "        name = [i for i in re.split('\\(주\\)|㈜| |\\xa0|주식회사', name) if not i==\"\"]\n",
    "        if len(name) > 1:\n",
    "            new_list.append(''.join([x for x in name if not any(word in x for word in remove_word)]))\n",
    "        else:\n",
    "            new_list.append(name[0])\n",
    "    \n",
    "    # 4. 그렇게 생성된 name_list와 우리가 가진 기업명(ind_name)을 매칭하여 기업명을 부여한다.\n",
    "    for i, name in enumerate(new_list):\n",
    "    \n",
    "        ## 매칭 점수 부여 (using fuzz matching: token_sort, token_set_ratio)\n",
    "        score = [fuzz.token_sort_ratio(name, key) for key in ind_name['trans_name']]\n",
    "        ## 해당 기업명이 ind_name 중에 하나를 포함하는지의 여부 \n",
    "        contain_index = [row[0] for row in ind_name.iterrows() if row[1]['trans_name'] in name]\n",
    "        contain_name = [key for key in ind_name['trans_name'] if key in name]\n",
    "\n",
    "        if len(contain_name) == 1: ## 포함 기준으로 가져온다.\n",
    "            data.loc[i, 'CODE'] = ind_name.loc[contain_index[0], 'CODE']\n",
    "            data.loc[i, 'ind_name'] = ind_name.loc[contain_index[0], 'name']\n",
    "\n",
    "        elif len(contain_name) == 0: ## 만약 포함되는 단어가 없을 경우, pass. (기업명 없다고 간주)\n",
    "            continue\n",
    "\n",
    "        else: ## 만약 여러개 ind_name을 포함할 경우, 그 중 가장 큰 score를 준 ind_name을 부여한다.\n",
    "            score = [score[x] for x in contain_index]\n",
    "            data.loc[i, 'CODE'] = ind_name['CODE'][contain_index[score.index(max(score))]]\n",
    "            data.loc[i, 'ind_name'] = ind_name['name'][contain_index[score.index(max(score))]]\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c73c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_protect_new = match_name(data=info_protect, col_name='기업명')\n",
    "info_protect_new.to_csv('S crawling/raw_정보보호_2021.csv', index=None, encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ddf511",
   "metadata": {},
   "source": [
    "#### 기업명 매칭을 거친 파일은 다시 열어 잘못 매칭된 기업들을 수정하고 엑셀 파일로 저장하였다.\n",
    "매칭되지 않은 기업 = -1 값은 모두 삭제하고 저장.  \n",
    "그렇게 수정된 파일: 정보보호_2021.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18384d98",
   "metadata": {},
   "source": [
    "## 3) 정보보호 현황 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "852b8bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE</th>\n",
       "      <th>ind_name</th>\n",
       "      <th>기업명</th>\n",
       "      <th>업종</th>\n",
       "      <th>게시일</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>AJ네트웍스 주식회사</td>\n",
       "      <td>임대업; 부동산 제외</td>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265520</td>\n",
       "      <td>AP시스템</td>\n",
       "      <td>에이피시스템(주)</td>\n",
       "      <td>기타 기계 및 장비 제조업</td>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>282330</td>\n",
       "      <td>BGF리테일</td>\n",
       "      <td>비지에프리테일</td>\n",
       "      <td>도매 및 상품 중개업</td>\n",
       "      <td>2022-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>079160</td>\n",
       "      <td>CJ CGV</td>\n",
       "      <td>씨제이씨지브이 주식회사</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>CJ대한통운</td>\n",
       "      <td>씨제이대한통운(주)</td>\n",
       "      <td>창고 및 운송관련 서비스업</td>\n",
       "      <td>2022-06-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CODE ind_name            기업명              업종        게시일\n",
       "0   95570   AJ네트웍스    AJ네트웍스 주식회사     임대업; 부동산 제외 2022-06-29\n",
       "1  265520    AP시스템      에이피시스템(주)  기타 기계 및 장비 제조업 2022-06-29\n",
       "2  282330   BGF리테일       비지에프리테일      도매 및 상품 중개업 2022-06-22\n",
       "3  079160   CJ CGV  씨제이씨지브이 주식회사              NaN 2022-06-02\n",
       "4     120   CJ대한통운    씨제이대한통운(주)   창고 및 운송관련 서비스업 2022-06-27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수정한 파일 load.\n",
    "data = pd.read_excel('S crawling/정보보호_2021.xlsx', dtype='object')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68bf6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'기업명':[], '작성된 기업명':[], '정보기술부문 투자액(A)':[], '정보기술부문 투자액(B)':[],\n",
    "                      '총임직원':[], '정보기술부문 인력(C)':[], '내부인력':[], '외부인력':[], '정보보호부문 전담인력(D) 계':[]})\n",
    "\n",
    "url = 'https://isds.kisa.or.kr/publish/list.do?pageNum=1&limit=700'\n",
    "path = \"chromedriver.exe\"\n",
    "\n",
    "wd = webdriver.Chrome(path)\n",
    "wd.maximize_window() #창 최대화\n",
    "\n",
    "\n",
    "## 크롤링 시작. ##\n",
    "for i, data_name in enumerate(data['기업명'].tolist()):\n",
    "    \n",
    "    # 사이트로 접속\n",
    "    wd.get(url)\n",
    "    wd.implicitly_wait(3)\n",
    "    \n",
    "    # name_list에서 해당 기업명 찾아서 인덱스 위치 클릭\n",
    "    names = wd.find_elements_by_xpath('/html/body/div/container/div/div/div[2]/div/table/tbody/tr/td[3]/a')\n",
    "    if i==0:\n",
    "        name_list = [name.get_attribute('innerText') for name in names]\n",
    "    time.sleep(1)\n",
    "\n",
    "    names[name_list.index(data_name)].click()\n",
    "    wd.implicitly_wait(3)\n",
    "    \n",
    "    \n",
    "    # 데이터 가져오기\n",
    "    new_list = [data_name]\n",
    "    \n",
    "    ## 기업명, inv A, B 추출\n",
    "    ### 데이터 값이 없는 경우 error. 이 경우 방지하기 위해 try문을 각각 씌워주었다. (id는 모두 동일)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"corpName\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"investAmountA\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"investAmountB\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    \n",
    "    ## 인력 데이터 추출\n",
    "    ### 데이터 값이 없는 경우 error. 이 경우 방지하기 위해 try문을 각각 씌워주었다. (id는 모두 동일)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"hrTotal\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"hrIt\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"hrItIn\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"hrItOut\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    try:\n",
    "        new_list.append(wd.find_element_by_xpath('//*[@id=\"hrItTotal\"]').get_attribute('value'))\n",
    "    except:\n",
    "        new_list.append(-1)\n",
    "    \n",
    "    ## 데이터 프레임에 리스트 데이터 삽입\n",
    "    result.loc[i] = new_list\n",
    "       \n",
    "time.sleep(10)\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9579af5",
   "metadata": {},
   "source": [
    "### 데이터프레임 merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701a973b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data와 추출된 result를 기업명(크롤링 통해서 추출된 기업명) 기준으로 merge.\n",
    "merge_DF = pd.merge(data, result, how='inner', on='기업명')\n",
    "merge_DF.rename(columns={'CODE':'종목코드', 'ind_name': '회사명'}, inplace=True)\n",
    "\n",
    "merge_DF.to_csv('S crawling/result/정보보호_2021.csv', encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
